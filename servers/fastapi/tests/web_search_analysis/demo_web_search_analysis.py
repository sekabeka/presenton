#!/usr/bin/env python3
"""
–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Å–∫—Ä–∏–ø—Ç –¥–ª—è Web Search Analysis Service

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç —Ä–∞–±–æ—Ç—É —Å–µ—Ä–≤–∏—Å–∞ —É–º–Ω–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–µ–±-–ø–æ–∏—Å–∫–∞.
"""

import asyncio
import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from services.web_search_analysis.llm_analyzer import LLMWebSearchAnalyzer
from services.web_search_analysis.enhanced_llm_client import EnhancedLLMClient
from services.web_search_analysis.models import QueryAnalysisRequest, WebSearchTrigger
from models.llm_message import LLMUserMessage


async def demo_basic_analysis():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –±–∞–∑–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–ø—Ä–æ—Å–æ–≤"""
    print("üîç –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –±–∞–∑–æ–≤–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–ø—Ä–æ—Å–æ–≤")
    print("=" * 50)
    
    analyzer = LLMWebSearchAnalyzer()
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã
    test_queries = [
        "Latest AI trends in 2024",
        "What is machine learning?",
        "Current statistics about AI adoption",
        "Recent news about ChatGPT",
        "How does neural networks work?",
        "Today's stock prices for tech companies",
        "Latest research papers on quantum computing"
    ]
    
    for query in test_queries:
        print(f"\nüìù –ó–∞–ø—Ä–æ—Å: '{query}'")
        
        try:
            request = QueryAnalysisRequest(
                user_query=query,
                presentation_context={"topic": "Technology"},
                sensitivity="medium",
                language="en"
            )
            
            analysis = await analyzer.analyze_query(request)
            
            print(f"   ‚úÖ –ù—É–∂–µ–Ω –≤–µ–±-–ø–æ–∏—Å–∫: {analysis.needs_web_search}")
            print(f"   üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {analysis.confidence:.2f}")
            print(f"   üéØ –¢—Ä–∏–≥–≥–µ—Ä—ã: {[t.value for t in analysis.triggers]}")
            print(f"   üí≠ –û–±–æ—Å–Ω–æ–≤–∞–Ω–∏–µ: {analysis.reasoning}")
            
            if analysis.suggested_queries:
                print(f"   üîç –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã: {analysis.suggested_queries}")
                
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞: {str(e)}")


async def demo_enhanced_llm_client():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ LLM –∫–ª–∏–µ–Ω—Ç–∞"""
    print("\n\nüöÄ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–≥–æ LLM –∫–ª–∏–µ–Ω—Ç–∞")
    print("=" * 50)
    
    client = EnhancedLLMClient()
    
    # –¢–µ—Å—Ç–æ–≤—ã–µ –∑–∞–ø—Ä–æ—Å—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
    test_queries = [
        "Latest AI trends in 2024",
        "What is artificial intelligence?",
        "Current market statistics for AI companies"
    ]
    
    for query in test_queries:
        print(f"\nüìù –ê–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞: '{query}'")
        
        try:
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω—É–∂–µ–Ω –ª–∏ –≤–µ–±-–ø–æ–∏—Å–∫
            needs_search = await client.should_enable_web_grounding(
                user_query=query,
                presentation_context={"topic": "Technology"}
            )
            
            print(f"   üîç –ù—É–∂–µ–Ω –≤–µ–±-–ø–æ–∏—Å–∫: {needs_search}")
            
            # –î–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ–º fallback –∞–Ω–∞–ª–∏–∑
            fallback_result = client._fallback_web_search_decision(query)
            print(f"   üîÑ Fallback —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {fallback_result}")
            
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞: {str(e)}")


async def demo_batch_analysis():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    print("\n\nüì¶ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
    print("=" * 50)
    
    analyzer = LLMWebSearchAnalyzer()
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞–∫–µ—Ç –∑–∞–ø—Ä–æ—Å–æ–≤
    queries = [
        QueryAnalysisRequest(
            user_query="Latest AI trends",
            presentation_context={"topic": "Technology"},
            sensitivity="high"
        ),
        QueryAnalysisRequest(
            user_query="What is machine learning?",
            presentation_context={"topic": "Education"},
            sensitivity="low"
        ),
        QueryAnalysisRequest(
            user_query="Current AI market statistics",
            presentation_context={"topic": "Business"},
            sensitivity="medium"
        )
    ]
    
    try:
        print("üîÑ –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–∞–∫–µ—Ç –∑–∞–ø—Ä–æ—Å–æ–≤...")
        analyses = await analyzer.batch_analyze(queries)
        
        print(f"‚úÖ –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ {len(analyses)} –∑–∞–ø—Ä–æ—Å–æ–≤")
        
        for i, analysis in enumerate(analyses):
            query_text = queries[i].user_query
            print(f"\nüìù –ó–∞–ø—Ä–æ—Å {i+1}: '{query_text}'")
            print(f"   üîç –ù—É–∂–µ–Ω –ø–æ–∏—Å–∫: {analysis.needs_web_search}")
            print(f"   üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {analysis.confidence:.2f}")
            print(f"   üéØ –¢—Ä–∏–≥–≥–µ—Ä—ã: {[t.value for t in analysis.triggers]}")
            
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}")


async def demo_multilingual_analysis():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –º–Ω–æ–≥–æ—è–∑—ã—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
    print("\n\nüåç –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –º–Ω–æ–≥–æ—è–∑—ã—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞")
    print("=" * 50)
    
    analyzer = LLMWebSearchAnalyzer()
    
    # –ú–Ω–æ–≥–æ—è–∑—ã—á–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
    multilingual_queries = [
        ("Latest AI trends in 2024", "en"),
        ("–ü–æ—Å–ª–µ–¥–Ω–∏–µ —Ç—Ä–µ–Ω–¥—ã –ò–ò –≤ 2024", "ru"),
        ("Tendencias recientes de IA en 2024", "es"),
        ("Tendances r√©centes de l'IA en 2024", "fr"),
        ("Neueste KI-Trends 2024", "de")
    ]
    
    for query, language in multilingual_queries:
        print(f"\nüìù –ó–∞–ø—Ä–æ—Å ({language}): '{query}'")
        
        try:
            request = QueryAnalysisRequest(
                user_query=query,
                presentation_context={"topic": "Technology"},
                sensitivity="medium",
                language=language
            )
            
            analysis = await analyzer.analyze_query(request)
            
            print(f"   üîç –ù—É–∂–µ–Ω –≤–µ–±-–ø–æ–∏—Å–∫: {analysis.needs_web_search}")
            print(f"   üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {analysis.confidence:.2f}")
            print(f"   üéØ –¢—Ä–∏–≥–≥–µ—Ä—ã: {[t.value for t in analysis.triggers]}")
            
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞: {str(e)}")


async def demo_sensitivity_levels():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–∑–Ω—ã—Ö —É—Ä–æ–≤–Ω–µ–π —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    print("\n\n‚öôÔ∏è –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —É—Ä–æ–≤–Ω–µ–π —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
    print("=" * 50)
    
    analyzer = LLMWebSearchAnalyzer()
    
    query = "AI technology overview"
    sensitivity_levels = ["low", "medium", "high"]
    
    for sensitivity in sensitivity_levels:
        print(f"\nüìù –ó–∞–ø—Ä–æ—Å: '{query}' (—á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {sensitivity})")
        
        try:
            request = QueryAnalysisRequest(
                user_query=query,
                presentation_context={"topic": "Technology"},
                sensitivity=sensitivity,
                language="en"
            )
            
            analysis = await analyzer.analyze_query(request)
            
            print(f"   üîç –ù—É–∂–µ–Ω –≤–µ–±-–ø–æ–∏—Å–∫: {analysis.needs_web_search}")
            print(f"   üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {analysis.confidence:.2f}")
            print(f"   üéØ –¢—Ä–∏–≥–≥–µ—Ä—ã: {[t.value for t in analysis.triggers]}")
            
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞: {str(e)}")


async def demo_trigger_types():
    """–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Ç—Ä–∏–≥–≥–µ—Ä–æ–≤"""
    print("\n\nüéØ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è —Ç–∏–ø–æ–≤ —Ç—Ä–∏–≥–≥–µ—Ä–æ–≤")
    print("=" * 50)
    
    analyzer = LLMWebSearchAnalyzer()
    
    # –ó–∞–ø—Ä–æ—Å—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Ç—Ä–∏–≥–≥–µ—Ä–æ–≤
    trigger_examples = [
        ("Latest AI trends in 2024", "temporal"),
        ("Breaking news about AI", "news"),
        ("AI market statistics 2024", "statistics"),
        ("Current events in AI", "current_events"),
        ("AI stock prices today", "prices"),
        ("Recent AI research papers", "research"),
        ("AI technology updates", "technology"),
        ("AI company financial reports", "finance"),
        ("What is artificial intelligence?", "general_knowledge")
    ]
    
    for query, expected_trigger in trigger_examples:
        print(f"\nüìù –ó–∞–ø—Ä–æ—Å: '{query}' (–æ–∂–∏–¥–∞–µ–º—ã–π —Ç—Ä–∏–≥–≥–µ—Ä: {expected_trigger})")
        
        try:
            request = QueryAnalysisRequest(
                user_query=query,
                presentation_context={"topic": "Technology"},
                sensitivity="medium",
                language="en"
            )
            
            analysis = await analyzer.analyze_query(request)
            
            print(f"   üîç –ù—É–∂–µ–Ω –≤–µ–±-–ø–æ–∏—Å–∫: {analysis.needs_web_search}")
            print(f"   üìä –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {analysis.confidence:.2f}")
            print(f"   üéØ –¢—Ä–∏–≥–≥–µ—Ä—ã: {[t.value for t in analysis.triggers]}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –æ–∂–∏–¥–∞–µ–º—ã–π —Ç—Ä–∏–≥–≥–µ—Ä
            trigger_values = [t.value for t in analysis.triggers]
            if expected_trigger in trigger_values:
                print(f"   ‚úÖ –û–∂–∏–¥–∞–µ–º—ã–π —Ç—Ä–∏–≥–≥–µ—Ä '{expected_trigger}' –Ω–∞–π–¥–µ–Ω!")
            else:
                print(f"   ‚ö†Ô∏è –û–∂–∏–¥–∞–µ–º—ã–π —Ç—Ä–∏–≥–≥–µ—Ä '{expected_trigger}' –Ω–µ –Ω–∞–π–¥–µ–Ω")
            
        except Exception as e:
            print(f"   ‚ùå –û—à–∏–±–∫–∞: {str(e)}")


async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏"""
    print("üéâ –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è Web Search Analysis Service")
    print("=" * 60)
    print("–≠—Ç–æ—Ç —Å–µ—Ä–≤–∏—Å —É–º–Ω–æ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω—É–∂–µ–Ω –ª–∏ –≤–µ–±-–ø–æ–∏—Å–∫ –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤")
    print("–Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LLM.\n")
    
    try:
        # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
        await demo_basic_analysis()
        await demo_enhanced_llm_client()
        await demo_batch_analysis()
        await demo_multilingual_analysis()
        await demo_sensitivity_levels()
        await demo_trigger_types()
        
        print("\n\nüéä –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
        print("=" * 60)
        print("–°–µ—Ä–≤–∏—Å –≥–æ—Ç–æ–≤ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é –≤ production!")
        
    except Exception as e:
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(e)}")
        print("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏.")


if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫–∞–µ–º –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—é
    asyncio.run(main())
